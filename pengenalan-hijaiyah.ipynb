{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import zipfile, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_zip = 'hijaiyah_Dataset.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip,'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/tmp/dataset8020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindir = '/tmp/dataset8020/train'\n",
    "label = []\n",
    "for subfolder in os.listdir(traindir):\n",
    "    for image in os.listdir(os.path.join(traindir, subfolder)):\n",
    "        label.append(subfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'1.Alif':0,\n",
    "            '2.Ba': 1,\n",
    "            '3.ta': 2,\n",
    "            '4.sa_':3 ,\n",
    "            '5.ja': 4,\n",
    "            '6.kha':5 ,\n",
    "            '7.kho': 6,\n",
    "            '8.da': 7,\n",
    "            '9.za_':8 ,\n",
    "            '10.ro': 9,\n",
    "            '11.za': 10,\n",
    "            '12.sa': 11,\n",
    "            '13.sya':12,\n",
    "            '14.syo': 13,\n",
    "            '15.do': 14,\n",
    "            '16.to': 15,\n",
    "            '17.zo': 16,\n",
    "            '18.ain':17, \n",
    "            '19.go': 18,\n",
    "            '20.fa': 19,\n",
    "            '21.qo': 20,\n",
    "            '22.ka': 21,\n",
    "            '23.la': 22,\n",
    "            '24.ma': 23,\n",
    "            '25.na': 24,\n",
    "            '26.wa': 25,\n",
    "            '27.ha': 26,\n",
    "            '28.ya': 27}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=20,\n",
    "                    horizontal_flip=True,\n",
    "                    shear_range = 0.2,\n",
    "                    fill_mode = 'nearest',\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5376 images belonging to 28 classes.\n",
      "Found 1344 images belonging to 28 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_dataset = train_datagen.flow_from_directory(batch_size=32,\n",
    "                                                 directory='/tmp/dataset8020/train',\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(128, 128), \n",
    "                                                 subset=\"training\",\n",
    "                                                  color_mode =\"grayscale\",\n",
    "                                                 class_mode='categorical',\n",
    "                                                 classes = classes\n",
    "                                                 )\n",
    "\n",
    "validation_dataset = train_datagen.flow_from_directory(batch_size=32,\n",
    "                                                 directory='/tmp/dataset8020/train',\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(128, 128), \n",
    "                                                 subset=\"validation\",\n",
    "                                                 color_mode =\"grayscale\",\n",
    "                                                 class_mode='categorical',\n",
    "                                                 classes = classes\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 126, 126, 32)      320       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 63, 63, 32)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 30, 30, 64)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 57600)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               7372928   \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 28)                1820      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,401,820\n",
      "Trainable params: 7,401,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (128, 128, 1)),\n",
    "    tf.keras.layers.AveragePooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.AveragePooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(28, activation = 'softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# callback membantu proses training agar lebih efisien, mulai dari early stop, check point, sampai dengan custom callback\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# modelFolder = 'model[0]/' #merupakan folder model yang menggunakan arsitektur neural network squensial,\n",
    "modelFolder = 'model[5]/' # merupakan folder model yang mengunakan arsitektur inception neural network v2\n",
    "\n",
    "# checkpoint ini memungkinkan weight disimpan pada saat loss training mencapai titik minimum\n",
    "checkpointLoss = ModelCheckpoint(f\"{modelFolder}bestLoss.hdf5\", \n",
    "                            monitor='loss', \n",
    "                            verbose=1,\n",
    "                            save_best_only=True, \n",
    "                            mode='auto')\n",
    "\n",
    "# checkpoint ini memungkinkan weight disimpan pada saat loss training pada tahap validation mencapai titik minimum\n",
    "checkpointValLoss = ModelCheckpoint(f\"{modelFolder}bestValLoss.hdf5\", \n",
    "                            monitor='val_loss', \n",
    "                            verbose=1,\n",
    "                            save_best_only=True, \n",
    "                            mode='auto')\n",
    "\n",
    "# checkpoint early stop memungkinkan model untuk langsung berhenti melakukan proses training ketika\n",
    "# tidak terdapat penurunan loss (semakin kecil locc semakin bagus). \n",
    "# patience = 10, menandakan model akan berhenti ketika tidak ada lagi minimum loss yang didapatkan selama 10 epochs berturut turut\n",
    "earlyStopVal = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "earlyStop = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=10)\n",
    "\n",
    "# callback khusus yang akan langsung memberhentikan model ketika sudah mencapain akurasi dan loss yang cukup, yakni 95% akurasi dengan loss 0.001\n",
    "class myCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.95 and logs.get('loss')<0.001):\n",
    "            print(\"\\nAkurasi telah mencapai > 95%! dan loss < 0.001\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.6816 - accuracy: 0.2003\n",
      "Epoch 1: val_loss improved from 3.10213 to 2.86527, saving model to model[5]\\bestValLoss.hdf5\n",
      "100/100 [==============================] - 131s 1s/step - loss: 2.6816 - accuracy: 0.2003 - val_loss: 2.8653 - val_accuracy: 0.2000\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.4389 - accuracy: 0.2612\n",
      "Epoch 2: val_loss improved from 2.86527 to 2.79656, saving model to model[5]\\bestValLoss.hdf5\n",
      "100/100 [==============================] - 127s 1s/step - loss: 2.4389 - accuracy: 0.2612 - val_loss: 2.7966 - val_accuracy: 0.2062\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 2.2587 - accuracy: 0.3175\n",
      "Epoch 3: val_loss improved from 2.79656 to 2.63621, saving model to model[5]\\bestValLoss.hdf5\n",
      "100/100 [==============================] - 127s 1s/step - loss: 2.2587 - accuracy: 0.3175 - val_loss: 2.6362 - val_accuracy: 0.2250\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.9795 - accuracy: 0.3953\n",
      "Epoch 4: val_loss did not improve from 2.63621\n",
      "100/100 [==============================] - 122s 1s/step - loss: 1.9795 - accuracy: 0.3953 - val_loss: 2.8190 - val_accuracy: 0.2313\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.8482 - accuracy: 0.4241\n",
      "Epoch 5: val_loss improved from 2.63621 to 2.58885, saving model to model[5]\\bestValLoss.hdf5\n",
      "100/100 [==============================] - 124s 1s/step - loss: 1.8482 - accuracy: 0.4241 - val_loss: 2.5889 - val_accuracy: 0.2937\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7368 - accuracy: 0.4622\n",
      "Epoch 6: val_loss did not improve from 2.58885\n",
      "100/100 [==============================] - 131s 1s/step - loss: 1.7368 - accuracy: 0.4622 - val_loss: 2.6883 - val_accuracy: 0.2375\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.6380 - accuracy: 0.4812\n",
      "Epoch 7: val_loss did not improve from 2.58885\n",
      "100/100 [==============================] - 126s 1s/step - loss: 1.6380 - accuracy: 0.4812 - val_loss: 2.6738 - val_accuracy: 0.3063\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.5036 - accuracy: 0.5247\n",
      "Epoch 8: val_loss did not improve from 2.58885\n",
      "100/100 [==============================] - 103s 1s/step - loss: 1.5036 - accuracy: 0.5247 - val_loss: 3.1034 - val_accuracy: 0.2500\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.4334 - accuracy: 0.5441\n",
      "Epoch 9: val_loss improved from 2.58885 to 2.22175, saving model to model[5]\\bestValLoss.hdf5\n",
      "100/100 [==============================] - 101s 1s/step - loss: 1.4334 - accuracy: 0.5441 - val_loss: 2.2218 - val_accuracy: 0.3313\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3806 - accuracy: 0.5456\n",
      "Epoch 10: val_loss did not improve from 2.22175\n",
      "100/100 [==============================] - 103s 1s/step - loss: 1.3806 - accuracy: 0.5456 - val_loss: 2.3641 - val_accuracy: 0.3187\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.3050 - accuracy: 0.5763\n",
      "Epoch 11: val_loss did not improve from 2.22175\n",
      "100/100 [==============================] - 108s 1s/step - loss: 1.3050 - accuracy: 0.5763 - val_loss: 2.4124 - val_accuracy: 0.3125\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.2485 - accuracy: 0.5994\n",
      "Epoch 12: val_loss did not improve from 2.22175\n",
      "100/100 [==============================] - 104s 1s/step - loss: 1.2485 - accuracy: 0.5994 - val_loss: 2.3983 - val_accuracy: 0.3250\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.1959 - accuracy: 0.6078\n",
      "Epoch 13: val_loss improved from 2.22175 to 2.17639, saving model to model[5]\\bestValLoss.hdf5\n",
      "100/100 [==============================] - 106s 1s/step - loss: 1.1959 - accuracy: 0.6078 - val_loss: 2.1764 - val_accuracy: 0.3500\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.1366 - accuracy: 0.6309\n",
      "Epoch 14: val_loss did not improve from 2.17639\n",
      "100/100 [==============================] - 107s 1s/step - loss: 1.1366 - accuracy: 0.6309 - val_loss: 2.5102 - val_accuracy: 0.3187\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.0888 - accuracy: 0.6500\n",
      "Epoch 15: val_loss did not improve from 2.17639\n",
      "100/100 [==============================] - 103s 1s/step - loss: 1.0888 - accuracy: 0.6500 - val_loss: 2.3827 - val_accuracy: 0.3313\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.0648 - accuracy: 0.6538\n",
      "Epoch 16: val_loss did not improve from 2.17639\n",
      "100/100 [==============================] - 149s 1s/step - loss: 1.0648 - accuracy: 0.6538 - val_loss: 2.2438 - val_accuracy: 0.4125\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.0188 - accuracy: 0.6697\n",
      "Epoch 17: val_loss did not improve from 2.17639\n",
      "100/100 [==============================] - 157s 2s/step - loss: 1.0188 - accuracy: 0.6697 - val_loss: 2.4542 - val_accuracy: 0.3562\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9995 - accuracy: 0.6822\n",
      "Epoch 18: val_loss did not improve from 2.17639\n",
      "100/100 [==============================] - 148s 1s/step - loss: 0.9995 - accuracy: 0.6822 - val_loss: 2.5284 - val_accuracy: 0.3375\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9545 - accuracy: 0.6994\n",
      "Epoch 19: val_loss improved from 2.17639 to 2.16181, saving model to model[5]\\bestValLoss.hdf5\n",
      "100/100 [==============================] - 144s 1s/step - loss: 0.9545 - accuracy: 0.6994 - val_loss: 2.1618 - val_accuracy: 0.4000\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9342 - accuracy: 0.7053\n",
      "Epoch 20: val_loss did not improve from 2.16181\n",
      "100/100 [==============================] - 144s 1s/step - loss: 0.9342 - accuracy: 0.7053 - val_loss: 2.4682 - val_accuracy: 0.3625\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9318 - accuracy: 0.7009\n",
      "Epoch 21: val_loss improved from 2.16181 to 2.10855, saving model to model[5]\\bestValLoss.hdf5\n",
      "100/100 [==============================] - 149s 1s/step - loss: 0.9318 - accuracy: 0.7009 - val_loss: 2.1086 - val_accuracy: 0.3938\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8783 - accuracy: 0.7050\n",
      "Epoch 22: val_loss did not improve from 2.10855\n",
      "100/100 [==============================] - 144s 1s/step - loss: 0.8783 - accuracy: 0.7050 - val_loss: 2.5533 - val_accuracy: 0.4250\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.8186 - accuracy: 0.7319\n",
      "Epoch 23: val_loss did not improve from 2.10855\n",
      "100/100 [==============================] - 145s 1s/step - loss: 0.8186 - accuracy: 0.7319 - val_loss: 2.1209 - val_accuracy: 0.4062\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7908 - accuracy: 0.7487\n",
      "Epoch 24: val_loss improved from 2.10855 to 1.95845, saving model to model[5]\\bestValLoss.hdf5\n",
      "100/100 [==============================] - 142s 1s/step - loss: 0.7908 - accuracy: 0.7487 - val_loss: 1.9584 - val_accuracy: 0.4875\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7604 - accuracy: 0.7506\n",
      "Epoch 25: val_loss improved from 1.95845 to 1.92695, saving model to model[5]\\bestValLoss.hdf5\n",
      "100/100 [==============================] - 141s 1s/step - loss: 0.7604 - accuracy: 0.7506 - val_loss: 1.9270 - val_accuracy: 0.4313\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7485 - accuracy: 0.7550\n",
      "Epoch 26: val_loss did not improve from 1.92695\n",
      "100/100 [==============================] - 147s 1s/step - loss: 0.7485 - accuracy: 0.7550 - val_loss: 2.0959 - val_accuracy: 0.5063\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7032 - accuracy: 0.7675\n",
      "Epoch 27: val_loss did not improve from 1.92695\n",
      "100/100 [==============================] - 145s 1s/step - loss: 0.7032 - accuracy: 0.7675 - val_loss: 2.0669 - val_accuracy: 0.3875\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7012 - accuracy: 0.7703\n",
      "Epoch 28: val_loss did not improve from 1.92695\n",
      "100/100 [==============================] - 144s 1s/step - loss: 0.7012 - accuracy: 0.7703 - val_loss: 2.0188 - val_accuracy: 0.4625\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6518 - accuracy: 0.7903\n",
      "Epoch 29: val_loss did not improve from 1.92695\n",
      "100/100 [==============================] - 139s 1s/step - loss: 0.6518 - accuracy: 0.7903 - val_loss: 2.3229 - val_accuracy: 0.5063\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6300 - accuracy: 0.7944\n",
      "Epoch 30: val_loss did not improve from 1.92695\n",
      "100/100 [==============================] - 141s 1s/step - loss: 0.6300 - accuracy: 0.7944 - val_loss: 2.7662 - val_accuracy: 0.3938\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6235 - accuracy: 0.7950\n",
      "Epoch 31: val_loss did not improve from 1.92695\n",
      "100/100 [==============================] - 139s 1s/step - loss: 0.6235 - accuracy: 0.7950 - val_loss: 2.8080 - val_accuracy: 0.3938\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6027 - accuracy: 0.8081\n",
      "Epoch 32: val_loss did not improve from 1.92695\n",
      "100/100 [==============================] - 135s 1s/step - loss: 0.6027 - accuracy: 0.8081 - val_loss: 2.3601 - val_accuracy: 0.4625\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6281 - accuracy: 0.8022\n",
      "Epoch 33: val_loss did not improve from 1.92695\n",
      "100/100 [==============================] - 133s 1s/step - loss: 0.6281 - accuracy: 0.8022 - val_loss: 2.4053 - val_accuracy: 0.4062\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6286 - accuracy: 0.8003\n",
      "Epoch 34: val_loss did not improve from 1.92695\n",
      "100/100 [==============================] - 147s 1s/step - loss: 0.6286 - accuracy: 0.8003 - val_loss: 2.6934 - val_accuracy: 0.4688\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5935 - accuracy: 0.8194\n",
      "Epoch 35: val_loss improved from 1.92695 to 1.71103, saving model to model[5]\\bestValLoss.hdf5\n",
      "100/100 [==============================] - 125s 1s/step - loss: 0.5935 - accuracy: 0.8194 - val_loss: 1.7110 - val_accuracy: 0.5063\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5842 - accuracy: 0.8134\n",
      "Epoch 36: val_loss did not improve from 1.71103\n",
      "100/100 [==============================] - 114s 1s/step - loss: 0.5842 - accuracy: 0.8134 - val_loss: 2.7567 - val_accuracy: 0.4187\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5047 - accuracy: 0.8363\n",
      "Epoch 37: val_loss did not improve from 1.71103\n",
      "100/100 [==============================] - 108s 1s/step - loss: 0.5047 - accuracy: 0.8363 - val_loss: 2.4724 - val_accuracy: 0.4375\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5111 - accuracy: 0.8319\n",
      "Epoch 38: val_loss did not improve from 1.71103\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.5111 - accuracy: 0.8319 - val_loss: 2.7287 - val_accuracy: 0.4313\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5125 - accuracy: 0.8397\n",
      "Epoch 39: val_loss did not improve from 1.71103\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.5125 - accuracy: 0.8397 - val_loss: 2.4474 - val_accuracy: 0.4812\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4927 - accuracy: 0.8422\n",
      "Epoch 40: val_loss did not improve from 1.71103\n",
      "100/100 [==============================] - 130s 1s/step - loss: 0.4927 - accuracy: 0.8422 - val_loss: 2.7155 - val_accuracy: 0.4625\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4861 - accuracy: 0.8444\n",
      "Epoch 41: val_loss did not improve from 1.71103\n",
      "100/100 [==============================] - 185s 2s/step - loss: 0.4861 - accuracy: 0.8444 - val_loss: 2.5987 - val_accuracy: 0.4313\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4466 - accuracy: 0.8512\n",
      "Epoch 42: val_loss did not improve from 1.71103\n",
      "100/100 [==============================] - 175s 2s/step - loss: 0.4466 - accuracy: 0.8512 - val_loss: 2.3872 - val_accuracy: 0.4938\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4533 - accuracy: 0.8594\n",
      "Epoch 43: val_loss did not improve from 1.71103\n",
      "100/100 [==============================] - 170s 2s/step - loss: 0.4533 - accuracy: 0.8594 - val_loss: 2.4821 - val_accuracy: 0.4812\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.8619\n",
      "Epoch 44: val_loss did not improve from 1.71103\n",
      "100/100 [==============================] - 176s 2s/step - loss: 0.4449 - accuracy: 0.8619 - val_loss: 2.2613 - val_accuracy: 0.5000\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.4154 - accuracy: 0.8691\n",
      "Epoch 45: val_loss did not improve from 1.71103\n",
      "100/100 [==============================] - 174s 2s/step - loss: 0.4154 - accuracy: 0.8691 - val_loss: 2.1357 - val_accuracy: 0.4750\n",
      "Epoch 45: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fc861f6440>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 1000\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=100,\n",
    "    epochs= epoch,\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=5,\n",
    "    callbacks = [callbacks, checkpointValLoss,earlyStopVal ]\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 1)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "test_image = image.load_img('alif.png', target_size=(128, 128), color_mode='grayscale')\n",
    "test_img = image.img_to_array(test_image)\n",
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.expand_dims(test_img, axis=0)\n",
    "images = np.vstack([test_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ini adalah 1.Alif\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(test_img)\n",
    "y_true = np.argmax(predict)\n",
    "result = list(classes.keys())[list(classes.values()).index(y_true)]\n",
    "print('ini adalah '+ result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2cd9076add9d1d8748a656baa357a1ac0e620fa125017f12a6540c62b41a0c68"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
